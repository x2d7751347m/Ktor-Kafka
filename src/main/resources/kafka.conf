ktor {
  kafka {
    # Required connection configs for Kafka producer, consumer, and admin
    bootstrap.servers = ["localhost:9092"]

    properties {
      security.protocol = SASL_SSL
      sasl.jaas.config = "org.apache.kafka.common.security.plain.PlainLoginModule     required username='user'     password='password';"
      sasl.mechanism = PLAIN
      # Required for correctness in Apache Kafka clients prior to 2.6
      client.dns.lookup = use_all_dns_ips
      # Best practice for Kafka producer to prevent data loss
      acks = all

      # Required connection configs for Confluent Cloud Schema Registry
      schema.registry.url = "sr_url"
      basic.auth.credentials.source = USER_INFO
      basic.auth.user.info = "key:pass"
    }
    consumer {
      group.id = "ktor-consumer"
      key.deserializer = org.apache.kafka.common.serialization.LongDeserializer
      value.deserializer = org.apache.kafka.common.serialization.DoubleDeserializer
    }
    producer {
      client.id = "ktor-producer"
      key.serializer = org.apache.kafka.common.serialization.LongSerializer
      value.serializer = io.confluent.kafka.serializers.json.KafkaJsonSchemaSerializer
    }
    streams {
      application.id = "ktor-stream"
      # TODO: cloud should be 3
      replication.factor = 3
      //cache.max.size.buffering = 1024
      cache.max.bytes.buffering = 0
      default.topic.replication.factor = 3
      //default.key.serde
      //default.value.serde
    }
  }
}